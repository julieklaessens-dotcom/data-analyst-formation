{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julieklaessens-dotcom/data-analyst-formation/blob/main/Notebook_Python_Functions_Week_40.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oq9G8h5EQ_8"
      },
      "source": [
        "# Semaine 40 — Notebook Python (Functions, Jupyter, Data Science)\n",
        "\n",
        "*Auteur :* Julie Klaessens  \n",
        "*Date :* 2025-09-29  \n",
        "*Objectif :* Continuer à apprendre les bases de Python pour la science des données : fonctions, Jupyter, data analysis, data cleaning, programmation orientée objet."
      ],
      "id": "2oq9G8h5EQ_8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SClT2O__EQ_-"
      },
      "source": [
        "## 1. Introduction\n",
        "Ce notebook compile mes exercices issus de **Dataquest (Part 1 — Cours 3‑4)** ."
      ],
      "id": "SClT2O__EQ_-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS_1FhWPEQ__"
      },
      "source": [
        "## 2. Python Functions and Jupyter Notebook"
      ],
      "id": "fS_1FhWPEQ__"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###      2.1 Python Functions: Arguments, Parameters, and Debugging"
      ],
      "metadata": {
        "id": "aNyDqK3kP5o7"
      },
      "id": "aNyDqK3kP5o7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wMCROmTEQ__",
        "outputId": "1d2e4e39-0f0e-4a2f-d19a-4e800e9da8c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Games': 3862, 'Productivity': 178, 'Weather': 72, 'Shopping': 122, 'Reference': 64, 'Finance': 104, 'Music': 138, 'Utilities': 248, 'Travel': 81, 'Social Networking': 167, 'Sports': 114, 'Business': 57, 'Health & Fitness': 180, 'Entertainment': 535, 'Photo & Video': 349, 'Navigation': 46, 'Education': 453, 'Lifestyle': 144, 'Food & Drink': 63, 'News': 75, 'Book': 112, 'Medical': 23, 'Catalogs': 10}\n",
            "{'4': 1626, '3.5': 702, '4.5': 2663, '5': 492, '3': 383, '2': 106, '2.5': 196, '0': 929, '1.5': 56, '1': 44}\n",
            "{'4': 1626, '3.5': 702, '4.5': 2663, '5': 492, '3': 383, '2': 106, '2.5': 196, '0': 929, '1.5': 56, '1': 44}\n",
            "1.7262178685562626\n"
          ]
        }
      ],
      "source": [
        "## 1. Extract Values from Any Column ##\n",
        "\n",
        "# --- Étape 1 : Monter Google Drive ---\n",
        "from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "# --- Étape 2 : Utiliser le bon chemin vers AppleStore.csv ---\n",
        "from csv import reader\n",
        "\n",
        "opened_file = open('/content/drive/MyDrive/Data/AppleStore.csv', encoding='utf-8')\n",
        "read_file = reader(opened_file)\n",
        "apps_data = list(read_file)\n",
        "\n",
        "# Extrait les valeurs de n'importe quelle colonne que nous voulons dans une liste séparée\n",
        "def extract(num_index):\n",
        "    new_list = []\n",
        "\n",
        "    for row in apps_data[1:]:\n",
        "        to_add = row[num_index]\n",
        "        new_list.append(to_add)\n",
        "\n",
        "    return new_list\n",
        "\n",
        "genres = extract(12)\n",
        "\n",
        "## 2. Creating Frequency Tables\n",
        "\n",
        "# Génère un tableau de fréquences pour une liste\n",
        "def freq_table(liste):\n",
        "    dico = {}\n",
        "    for key in liste:\n",
        "        if key in dico:\n",
        "            dico[key] += 1\n",
        "        else:\n",
        "            dico[key] = 1\n",
        "    return dico\n",
        "\n",
        "genres_ft = freq_table(genres)\n",
        "\n",
        "print(genres_ft)\n",
        "\n",
        "## 3. Writing a Single Function\n",
        "\n",
        "# Génère une table de fréquences pour n'importe quelle colonne de l'ensemble de données d'applications iOS\n",
        "def freq_table(index):\n",
        "    table_freq ={}\n",
        "\n",
        "    for row in apps_data[1:]:\n",
        "        value = row[index]\n",
        "        if value in table_freq:\n",
        "            table_freq[value] += 1\n",
        "        else:\n",
        "            table_freq[value] = 1\n",
        "\n",
        "    return table_freq\n",
        "\n",
        "ratings_ft = freq_table(8)\n",
        "\n",
        "print(ratings_ft)\n",
        "\n",
        "## 4. Reusability and Multiple Parameters\n",
        "\n",
        "# Génère une table de fréquences pour n'importe quelle colonne de n'importe quel ensemble de données\n",
        "def freq_table(data_set, index):\n",
        "    frequency_table = {}\n",
        "\n",
        "    for row in data_set[1:]:\n",
        "        value = row[index]\n",
        "        if value in frequency_table:\n",
        "            frequency_table[value] += 1\n",
        "        else:\n",
        "            frequency_table[value] = 1\n",
        "\n",
        "    return frequency_table\n",
        "\n",
        "ratings_ft = freq_table(apps_data, 8)\n",
        "\n",
        "print(ratings_ft)\n",
        "\n",
        "## 5. Combining Functions\n",
        "\n",
        "def extract(data_set, index):\n",
        "    column = []\n",
        "    for row in data_set[1:]:\n",
        "        value = row[index]\n",
        "        column.append(value)\n",
        "    return column\n",
        "\n",
        "def find_sum(a_list):\n",
        "    a_sum = 0\n",
        "    for element in a_list:\n",
        "        a_sum += float(element)\n",
        "    return a_sum\n",
        "\n",
        "def find_length(a_list):\n",
        "    length = 0\n",
        "    for element in a_list:\n",
        "        length += 1\n",
        "    return length\n",
        "\n",
        "# Calcule la moyenne de n’importe quelle colonne dans un ensemble de données\n",
        "def mean(data_set, index):\n",
        "    column = extract(data_set, index)\n",
        "    a_sum = find_sum(column)\n",
        "    length = find_length(column)\n",
        "    return a_sum/length\n",
        "\n",
        "avg_price = mean(apps_data, 5)\n",
        "print(avg_price)"
      ],
      "id": "2wMCROmTEQ__"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Python Functions: Returning Multiple Variables and Function Scopes"
      ],
      "metadata": {
        "id": "fiDFXxJvvM3C"
      },
      "id": "fiDFXxJvvM3C"
    },
    {
      "cell_type": "code",
      "source": [
        "## 1. Returning Multiple Variables\n",
        "\n",
        "# Cette fonction retourne un tuple (a, b, c)\n",
        "def pythagorean(a, b):\n",
        "    a_squared = a**2\n",
        "    b_squared = b**2\n",
        "    c_squared = a_squared + b_squared\n",
        "    return a_squared, b_squared, c_squared\n",
        "\n",
        "print(pythagorean(5, 12))\n",
        "\n",
        "## 2. Tuples\n",
        "\n",
        "def open_dataset(file_name='AppleStore.csv', header=True):\n",
        "    opened_file = open(file_name)\n",
        "    from csv import reader\n",
        "    read_file = reader(opened_file)\n",
        "    data = list(read_file)\n",
        "\n",
        "    if header:\n",
        "        return data[0], data[1:]\n",
        "    else:\n",
        "        return data\n",
        "\n",
        "all_data = open_dataset()\n",
        "header = all_data[0]\n",
        "apps_data = all_data[1]\n",
        "# on peut aussi faire directement : header, apps_data = open_dataset()\n"
      ],
      "metadata": {
        "id": "CEsgJr2EvSqD"
      },
      "id": "CEsgJr2EvSqD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Guided Project: Profitable App Profiles for the App Store and Google Play Markets"
      ],
      "metadata": {
        "id": "BnYfjFPxGPCW"
      },
      "id": "BnYfjFPxGPCW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "See project here : [\"Project_Basics\"](https://colab.research.google.com/drive/1Fqm-uGx2WzgEwCasWu3aSfLlobHn8cC9)"
      ],
      "metadata": {
        "id": "CdhF1bDuEAJm"
      },
      "id": "CdhF1bDuEAJm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Intermediate Python for Data Science"
      ],
      "metadata": {
        "id": "3c76BEFExlQL"
      },
      "id": "3c76BEFExlQL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Cleaning and Preparing Data in Python"
      ],
      "metadata": {
        "id": "OaG3UrSFUJy5"
      },
      "id": "OaG3UrSFUJy5"
    },
    {
      "cell_type": "code",
      "source": [
        "## 1. Reading a dataset\n",
        "\n",
        "from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "# import the reader function from the csv module\n",
        "from csv import reader\n",
        "\n",
        "# use the python built-in function open()\n",
        "# to open the children.csv file\n",
        "with open('/content/drive/MyDrive/Data/artworks.csv', encoding='utf-8') as file:\n",
        "\n",
        "    # use csv.reader() to parse the data from\n",
        "    # the opened file\n",
        "    read_file = reader(file)\n",
        "\n",
        "    # use list() to convert the read file\n",
        "    # into a list of lists format\n",
        "    moma = list(read_file)\n",
        "\n",
        "# remove the first row of the data, which\n",
        "# contains the column names\n",
        "moma = moma[1:]\n",
        "\n",
        "# Write your code here\n",
        "\n",
        "## 2. Removing the brackets \"()\"\n",
        "\n",
        "for row in moma:\n",
        "    nationality = row[2]\n",
        "    nationality = nationality.replace(\"(\",\"\")\n",
        "    nationality = nationality.replace(\")\",\"\")\n",
        "    row[2] = nationality\n",
        "\n",
        "    genre = row[5]\n",
        "    genre = genre.replace(\"(\",\"\")\n",
        "    genre = genre.replace(\")\",\"\")\n",
        "    row[5] = genre\n",
        "\n",
        "## 3. String Capitalization\n",
        "\n",
        "for row in moma:\n",
        "    gender = row[5]\n",
        "\n",
        "    # convert the gender to title case\n",
        "    gender = gender.title()\n",
        "\n",
        "    # if there is no gender, set\n",
        "    # a descriptive value\n",
        "    if not gender == \"\": # on peut aussi écrire if gender == \"\":\n",
        "        gender = \"Gender Unknown/Other\"\n",
        "    row[5] = gender\n",
        "\n",
        "    nationality = row[2]\n",
        "    nationality = nationality.title()\n",
        "\n",
        "    if nationality ==\"\":\n",
        "        nationality = \"Nationality Unknown\"\n",
        "    row[2] = nationality\n",
        "print(moma[31])\n",
        "\n",
        "## 4. Errors During Data Cleaning\n",
        "\n",
        "# Remove the parentheses from the beginning and the end of each date value and convert the values from the string type to an integer type\n",
        "def clean_and_convert(date):\n",
        "    # check that we don't have an empty string\n",
        "    if date != \"\":\n",
        "        # move the rest of the function inside\n",
        "        # the if statement\n",
        "        date = date.replace(\"(\", \"\")\n",
        "        date = date.replace(\")\", \"\")\n",
        "        date = int(date)\n",
        "    return date\n",
        "\n",
        "# Clean the date columns\n",
        "for row in moma:\n",
        "    begin_date = row[3]\n",
        "    end_date = row[4]\n",
        "    begin_date = clean_and_convert(begin_date)\n",
        "    end_date = clean_and_convert(end_date)\n",
        "    row[3] = begin_date\n",
        "    row[4] = end_date\n",
        "\n",
        "## 5. Parsing Numbers from Complex Strings\n",
        "\n",
        "test_data = [\"1912\", \"1929\", \"1913-1923\",\n",
        "             \"(1951)\", \"1994\", \"1934\",\n",
        "             \"c. 1915\", \"1995\", \"c. 1912\",\n",
        "             \"(1988)\", \"2002\", \"1957-1959\",\n",
        "             \"c. 1955.\", \"c. 1970's\",\n",
        "             \"C. 1990-1999\"]\n",
        "\n",
        "bad_chars = [\"(\",\")\",\"c\",\"C\",\".\",\"s\",\"'\", \" \"]\n",
        "\n",
        "def strip_characters(string):\n",
        "    for char in bad_chars:\n",
        "        string = string.replace(char,\"\")\n",
        "    return string\n",
        "\n",
        "stripped_test_data = []\n",
        "\n",
        "for key in test_data:\n",
        "    key = strip_characters(key)\n",
        "    stripped_test_data.append(key)\n",
        "\n",
        "stripped_test_data = ['1912', '1929', '1913-1923',\n",
        "                      '1951', '1994', '1934',\n",
        "                      '1915', '1995', '1912',\n",
        "                      '1988', '2002', '1957-1959',\n",
        "                      '1955', '1970', '1990-1999']\n",
        "\n",
        "def process_date(string):\n",
        "    if \"-\" in string:\n",
        "        string = string.split(\"-\")\n",
        "        date = round((int(string[0]) + int(string[1])) / 2)\n",
        "    else:\n",
        "        date = int(string)\n",
        "    return date\n",
        "\n",
        "processed_test_data = []\n",
        "for string in stripped_test_data:\n",
        "    date = process_date(string)\n",
        "    processed_test_data.append(date)\n",
        "\n",
        "# Clean the column date in order to have only date characters as integers\n",
        "for string in moma:\n",
        "    date = string[6]\n",
        "    date = strip_characters(date)\n",
        "    date = process_date(date)\n",
        "    string[6] = date\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIIY-r0jUSDC",
        "outputId": "c322f771-b21d-4d90-d619-bae0eca81c67"
      },
      "id": "TIIY-r0jUSDC",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Untitled', 'Unknown', 'Nationality Unknown', '', '', '', 'c. 1925', 'Photography']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Python Data Analysis Basics"
      ],
      "metadata": {
        "id": "f_qrb4fqEl72"
      },
      "id": "f_qrb4fqEl72"
    },
    {
      "cell_type": "code",
      "source": [
        "## 1. Reading the MoMA Dataset\n",
        "\n",
        "from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "# import the reader function from the csv module\n",
        "from csv import reader\n",
        "\n",
        "# use the python built-in function open()\n",
        "# to open the children.csv file\n",
        "with open('/content/drive/MyDrive/Data/artworks_clean.csv', encoding='utf-8') as file:\n",
        "\n",
        "    # use csv.reader() to parse the data from\n",
        "    # the opened file\n",
        "    read_file = reader(file)\n",
        "\n",
        "    # use list() to convert the read file\n",
        "    # into a list of lists format\n",
        "    moma = list(read_file)\n",
        "\n",
        "# remove the first row of the data, which\n",
        "# contains the column names\n",
        "moma = moma[1:]\n",
        "\n",
        "# Convert the birthdate values\n",
        "for row in moma:\n",
        "    birth_date = row[3]\n",
        "    if birth_date != \"\":\n",
        "        birth_date = int(birth_date)\n",
        "    row[3] = birth_date\n",
        "\n",
        "# Convert the death date values\n",
        "for row in moma:\n",
        "    death_date = row[4]\n",
        "    if death_date != \"\":\n",
        "        death_date = int(death_date)\n",
        "    row[4] = death_date\n",
        "\n",
        "# Write your code below\n",
        "for row in moma:\n",
        "    date = row[6]\n",
        "    if date != \"\":\n",
        "        date = int(date)\n",
        "    row[6] = date\n",
        "\n",
        "\n",
        "## 2. Calculating Artist Ages\n",
        "\n",
        "ages = []\n",
        "for row in moma:\n",
        "    date = row[6]\n",
        "    birth = row[3]\n",
        "    if type(birth) == int:\n",
        "        age = date - birth\n",
        "    else:\n",
        "        age = 0\n",
        "    ages.append(age)\n",
        "\n",
        "final_ages = []\n",
        "for age in ages:\n",
        "    if age >= 20:\n",
        "        final_age = age\n",
        "    else:\n",
        "        final_age = \"Unknown\"\n",
        "    final_ages.append(final_age)\n",
        "\n",
        "\n",
        "## 3. Converting Ages to Decades\n",
        "\n",
        "decades = []\n",
        "for age in final_ages:\n",
        "    if age == \"Unknown\":\n",
        "        decade = age\n",
        "    else:\n",
        "        decade = str(age)\n",
        "        decade = decade[:-1]\n",
        "        decade += \"0s\"\n",
        "    decades.append(decade)\n",
        "\n",
        "\n",
        "## 4. Summarizing the Decade Data\n",
        "\n",
        "# frequency table\n",
        "decade_frequency = {}\n",
        "for key in decades:\n",
        "    if key not in decade_frequency:\n",
        "        decade_frequency[key] = 1\n",
        "    else:\n",
        "        decade_frequency[key] += 1\n",
        "\n",
        "## 5. Creating an Artist Frequency Table\n",
        "\n",
        "artist_freq = {}\n",
        "for key in moma:\n",
        "    artist = key[1]\n",
        "    if artist not in artist_freq:\n",
        "        artist_freq[artist] = 1\n",
        "    else:\n",
        "        artist_freq[artist] += 1\n",
        "\n",
        "## 6. Creating an Artist Summary Function\n",
        "\n",
        "def artist_summary(artist):\n",
        "  num_artworks = artist_freq[artist]\n",
        "  f_string = f\"There are {num_artworks} artworks by {artist} in the dataset\"\n",
        "  print(f_string)\n",
        "\n",
        "## 7. Summarizing Artwork Gender Data\n",
        "\n",
        "gender_freq = {}\n",
        "for row in moma:\n",
        "    gender = row[5]\n",
        "    if gender not in gender_freq:\n",
        "        gender_freq[gender] = 1\n",
        "    else:\n",
        "        gender_freq[gender] += 1\n",
        "\n",
        "for gender, qty in gender_freq.items():\n",
        "    output = f\"There are {qty:,} artworks by {gender} artists\"\n",
        "    print(output)"
      ],
      "metadata": {
        "id": "jhWSLBjTElYx"
      },
      "id": "jhWSLBjTElYx",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 Object-Oriented Python"
      ],
      "metadata": {
        "id": "SNlrZtq3r1cN"
      },
      "id": "SNlrZtq3r1cN"
    },
    {
      "cell_type": "code",
      "source": [
        "## 1. Introduction ##\n",
        "\n",
        "l = [1, 2, 3]\n",
        "s = \"string\"\n",
        "d = {\"a\": 1, \"b\": 2}\n",
        "\n",
        "print(type(l))\n",
        "print(type(s))\n",
        "print(type(d))\n",
        "\n",
        "## 3. Defining a Class ##\n",
        "\n",
        "class MyClass:\n",
        "    pass\n",
        "\n",
        "## 4. Instantiating a Class ##\n",
        "\n",
        "class MyClass:\n",
        "    pass\n",
        "\n",
        "my_instance = MyClass()\n",
        "print(type(my_instance))\n",
        "\n",
        "## 6. Understanding \"self\" ##\n",
        "\n",
        "class MyClass:\n",
        "\n",
        "    def first_method(self):\n",
        "        return \"This is my first method\"\n",
        "\n",
        "my_instance = MyClass()\n",
        "result = my_instance.first_method()\n",
        "\n",
        "## 7. Creating a Method that Accepts an Argument ##\n",
        "\n",
        "class MyClass:\n",
        "\n",
        "    def first_method(self):\n",
        "        return \"This is my first method\"\n",
        "\n",
        "    # Add method here\n",
        "    def return_list(self, input_list):\n",
        "        return input_list\n",
        "\n",
        "my_instance = MyClass()\n",
        "result = my_instance.return_list([1, 2, 3])\n",
        "\n",
        "## 8. Attributes and the Init Method ##\n",
        "\n",
        "class MyList():\n",
        "    def __init__(self, initial_data):\n",
        "        self.data = initial_data\n",
        "\n",
        "my_list = MyList([1, 2, 3, 4, 5])\n",
        "print(my_list.data)\n",
        "\n",
        "## 9. Creating an Append Method ##\n",
        "\n",
        "class MyList:\n",
        "\n",
        "    def __init__(self, initial_data):\n",
        "        self.data = initial_data\n",
        "\n",
        "    # Add method here\n",
        "    def append(self, new_item):\n",
        "        self.data += [new_item]\n",
        "\n",
        "my_list = MyList([1, 2, 3, 4, 5])\n",
        "print(my_list.data)\n",
        "my_list.append(6)\n",
        "print(my_list.data)\n",
        "\n",
        "## 10. Creating and Updating an Attribute ##\n",
        "\n",
        "class MyList:\n",
        "\n",
        "    def __init__(self, initial_data):\n",
        "        self.data = initial_data\n",
        "        # Calculate the initial length\n",
        "        self.length = 0\n",
        "        for item in self.data:\n",
        "            self.length += 1\n",
        "\n",
        "    def append(self, new_item):\n",
        "        self.data = self.data + [new_item]\n",
        "        # Update the length here\n",
        "        self.length += 1\n",
        "\n",
        "my_list = MyList([1, 1, 2, 3, 5])\n",
        "print(my_list.length)\n",
        "my_list.append(8)\n",
        "print(my_list.length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiZgqYnPulhF",
        "outputId": "265263de-e308-4143-b5c7-b93a64b44858"
      },
      "id": "QiZgqYnPulhF",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class '__main__.MyClass'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4 Working with Dates and Times in Python"
      ],
      "metadata": {
        "id": "FhKecKPUmAed"
      },
      "id": "FhKecKPUmAed"
    },
    {
      "cell_type": "code",
      "source": [
        "## 1. Introduction ##\n",
        "\n",
        "# --- Étape 1 : Monter Google Drive ---\n",
        "from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "# --- Étape 2 : Utiliser le bon chemin vers csv ---\n",
        "from csv import reader\n",
        "\n",
        "opened_file = open('/content/drive/MyDrive/Data/potus_visitors_2015.csv', encoding='utf-8')\n",
        "read_file = reader(opened_file)\n",
        "potus = list(read_file)\n",
        "potus = potus[1:]\n",
        "\n",
        "## 3. The Datetime Module ##\n",
        "\n",
        "import datetime as dt\n",
        "\n",
        "## 4. The Datetime Class ##\n",
        "\n",
        "import datetime as dt\n",
        "\n",
        "ibm_founded = dt.datetime(1911, 6, 16)\n",
        "man_on_moon = dt.datetime(1969, 7, 20, 20, 17)\n",
        "\n",
        "## 5. Using Strptime to Parse Strings as Dates ##\n",
        "\n",
        "# The `potus` list of lists is available from\n",
        "# the earlier screen where we created it\n",
        "\n",
        "date_format = \"%m/%d/%y %H:%M\"\n",
        "\n",
        "for row in potus:\n",
        "    appt_start_date = row[2]\n",
        "    appt_start_date_dt = dt.datetime.strptime(appt_start_date, date_format)\n",
        "    row[2] = appt_start_date_dt\n",
        "\n",
        "## 6. Using Strftime to Format Dates ##\n",
        "\n",
        "visitors_per_month = {}\n",
        "\n",
        "for row in potus:\n",
        "    appt_start_date = row[2]\n",
        "    appt_start_date_dt = appt_start_date.strftime(\"%B, %Y\")\n",
        "    if appt_start_date_dt not in visitors_per_month:\n",
        "        visitors_per_month[appt_start_date_dt] = 1\n",
        "    else:\n",
        "        visitors_per_month[appt_start_date_dt] += 1\n",
        "\n",
        "## 7. The Time Class ##\n",
        "\n",
        "appt_times = []\n",
        "\n",
        "for row in potus:\n",
        "    t = row[2]\n",
        "    t_time = t.time()\n",
        "    appt_times.append(t_time)\n",
        "\n",
        "## 8. Comparing Time Objects ##\n",
        "\n",
        "min_time = min(appt_times)\n",
        "max_time = max(appt_times)\n",
        "\n",
        "## 9. Calculations with Dates and Times ##\n",
        "\n",
        "dt_1 = dt.datetime(1981, 1, 31)\n",
        "dt_2 = dt.datetime(1984, 6, 28)\n",
        "dt_3 = dt.datetime(2016, 5, 24)\n",
        "dt_4 = dt.datetime(2001, 1, 1, 8, 24, 13)\n",
        "\n",
        "answer_1 = dt_2 - dt_1\n",
        "answer_2 = dt_3 + dt.timedelta(56)\n",
        "answer_3 = dt_4 - dt.timedelta(seconds=3600)\n",
        "\n",
        "## 10. Summarizing Appointment Lengths ##\n",
        "\n",
        "for row in potus:\n",
        "    end_date = row[3]\n",
        "    end_date = dt.datetime.strptime(end_date, \"%m/%d/%y %H:%M\")\n",
        "    row[3] = end_date\n",
        "\n",
        "appt_lengths = {}\n",
        "for row in potus:\n",
        "    start_date = row[2]\n",
        "    end_date = row[3]\n",
        "    length = end_date - start_date\n",
        "    if length not in appt_lengths:\n",
        "        appt_lengths[length] = 1\n",
        "    else:\n",
        "        appt_lengths[length] += 1\n",
        "\n",
        "min_length = min(appt_lengths)\n",
        "max_length = max(appt_lengths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ypj3CHmlUBO",
        "outputId": "01f2e0eb-28d5-43e8-89e7-531253e12e4c"
      },
      "id": "7ypj3CHmlUBO",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Guided Project: Exploring Hacker News Posts"
      ],
      "metadata": {
        "id": "rUnEaPBLZbuw"
      },
      "id": "rUnEaPBLZbuw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, we'll work with a dataset of submissions to popular technology site [Hacker News](https://news.ycombinator.com/). Hacker News is a site started by the startup incubator Y Combinator, where user-submitted stories (known as \\\"posts\\\") receive votes and comments, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of the Hacker News listings can get hundreds of thousands of visitors as a result.\n",
        "\n",
        "We'll compare these two types of posts to determine the following:\n",
        "\n",
        "*   Do `Ask HN` or `Show HN` receive more comments on average?\n",
        "*   Do posts created at a certain time receive more comments on average?\""
      ],
      "metadata": {
        "id": "Tw2FUyhwZnAN"
      },
      "id": "Tw2FUyhwZnAN"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Étape 1 : Monter Google Drive ---\n",
        "from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "# --- Étape 2 : Utiliser le bon chemin vers csv ---\n",
        "from csv import reader\n",
        "\n",
        "opened_file = open('/content/drive/MyDrive/Data/hacker_news.csv', encoding='utf-8')\n",
        "read_file = reader(opened_file)\n",
        "hn = list(read_file)\n",
        "\n",
        "print(hn[:5])\n",
        "\n",
        "# Removing the first line containging the column headers\n",
        "headers = hn[0]\n",
        "hn = hn[1:]\n",
        "print(headers)\n",
        "print(hn[:5])\n",
        "\n",
        "# Identify which posts begin with \\\"ASK HN\\\" and with \\\"Show HN\\\"\n",
        "ask_posts = []\n",
        "show_posts = []\\\n",
        "\n",
        "other_posts = []\n",
        "for row in hn:\n",
        "    title = row[1]\n",
        "    if title.lower().startswith('ask hn'):\n",
        "        ask_posts.append(row)\n",
        "    elif title.lower().startswith('show hn'):\n",
        "        show_posts.append(row)\n",
        "    else:\n",
        "        other_posts.append(row)\n",
        "\n",
        "print(len(ask_posts))\n",
        "print(len(show_posts))\n",
        "print(len(other_posts))\n",
        "\n",
        "# determine if ask posts or show posts receive more comments on average\n",
        "total_ask_comments = 0\n",
        "for key in ask_posts:\n",
        "    total_ask_comments += float(key[4])\n",
        "    avg_ask_comments = total_ask_comments/len(ask_posts)\n",
        "print(\"'Ask HN' posts: \", avg_ask_comments)\n",
        "\n",
        "total_show_comments = 0\n",
        "for key in show_posts:\n",
        "    total_show_comments += float(key[4])\n",
        "    avg_show_comments = total_show_comments/len(show_posts)\n",
        "print(\"'Show HN' posts: \", avg_show_comments)\n",
        "\n",
        "# Calculate the number of ask posts created per hour, along with the total number of comments\n",
        "import datetime as dt\n",
        "\n",
        "result_list = []\n",
        "\n",
        "for key in ask_posts:\n",
        "    created_at = key[6]\n",
        "    ask_comments = int(key[4])\n",
        "    result_list.append([created_at, ask_comments])\n",
        "\n",
        "counts_by_hour = {} # will contain the number of ask posts created during each hour of the day\n",
        "comments_by_hour = {} # will contain the corresponding number of comments ask posts created at each hour received\n",
        "\n",
        "for row in result_list:\n",
        "    date = row[0]\n",
        "    comments = row[1]\n",
        "    time = dt.datetime.strptime(date,\"%m/%d/%Y %H:%M\").strftime(\"%H\") # extrait l'heure de la date\n",
        "    if time not in counts_by_hour:\n",
        "        counts_by_hour[time] = 1\n",
        "        comments_by_hour[time] = comments\n",
        "    else:\n",
        "        counts_by_hour[time] += 1\n",
        "        comments_by_hour[time] += comments\n",
        "\n",
        "comments_by_hour\n",
        "\n",
        "\n",
        "# Calculate the average number of comments for posts created during each hour of the day\n",
        "\n",
        "avg_by_hour = []\n",
        "\n",
        "for hr in comments_by_hour:\n",
        "    avg_by_hour.append([hr, comments_by_hour[hr]/counts_by_hour[hr]])\n",
        "\n",
        "avg_by_hour\n",
        "\n",
        "swap_avg_by_hour = []\n",
        "\n",
        "for row in avg_by_hour:\n",
        "    swap_avg_by_hour.append([row[1], row[0]])\n",
        "\n",
        "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
        "\n",
        "print(\"Top 5 Hours for Ask Posts Comments\")\n",
        "\n",
        "for avg, hr in sorted_swap[:5]:\n",
        "    print(f\"{dt.datetime.strptime(hr, '%H').strftime('%H:%M')}: {avg: .2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXexk4-UYu8g",
        "outputId": "2ccb783b-e6ce-498b-ac44-59373ea90092"
      },
      "id": "UXexk4-UYu8g",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']]\n",
            "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
            "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n",
            "1744\n",
            "1162\n",
            "17194\n",
            "'Ask HN' posts:  14.038417431192661\n",
            "'Show HN' posts:  10.31669535283993\n",
            "Top 5 Hours for Ask Posts Comments\n",
            "15:00:  38.59\n",
            "02:00:  23.81\n",
            "20:00:  21.52\n",
            "16:00:  16.80\n",
            "21:00:  16.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kCxCQRXERAA"
      },
      "source": [
        "## 6. Conclusion\n",
        "- Ce que j’ai appris :\n",
        "\n",
        "  *   Using Built-in Functions and Creating Functions\n",
        "  *   Functions: Arguments, Parameters, and Debugging:\n",
        "  *   Built-in Functions and Multiple Return Statements\n",
        "  *   Returning Multiple Variables and Function Scopes   \n",
        "  *   Jupyter Notebook\n",
        "  *   Cleaning and Preparing Data\n",
        "  *   Data Analysis Basics\n",
        "  *   Basics of Object-Oriented Python\n",
        "  *   Working with Dates and Times\n",
        "\n",
        "- Références : [Dataquest Part 1 (Cours 3‑4)](https://www.dataquest.io/path/data-analyst/)"
      ],
      "id": "6kCxCQRXERAA"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
