{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julieklaessens-dotcom/data-analyst-formation/blob/main/Notebook_Python_NumPy%26Panda_Week_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oq9G8h5EQ_8"
      },
      "source": [
        "# Semaine 3 — Notebook Python (Numpy & Pandas)\n",
        "\n",
        "*Auteur :* Julie Klaessens  \n",
        "*Date :* 2025-10-09  \n",
        "*Objectif :* Découvrir comment optimiser son code à l'aide des deux bibliothèques Python les plus populaires : NumPy et pandas. Ces bibliothèques  permettent de programmer plus efficacement et de gagner du temps."
      ],
      "id": "2oq9G8h5EQ_8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SClT2O__EQ_-"
      },
      "source": [
        "## 1. Introduction\n",
        "Ce notebook compile mes exercices issus de **Dataquest (Introduction to Pandas and NumPy for Data Analysis)**."
      ],
      "id": "SClT2O__EQ_-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS_1FhWPEQ__"
      },
      "source": [
        "## 2. Introduction to Pandas and NumPy for Data Analysis"
      ],
      "id": "fS_1FhWPEQ__"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###      2.1 Introduction to NumPy"
      ],
      "metadata": {
        "id": "aNyDqK3kP5o7"
      },
      "id": "aNyDqK3kP5o7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wMCROmTEQ__",
        "outputId": "1d2c6008-31a3-4fb6-c44d-e8484dfb2bd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "(2013, 15)\n",
            "[52.8 46.3 37.8 ... 52.8 35.8 49.3]\n",
            "[37.11340206 38.58157895 31.27222982 25.88429752 26.3715415  38.53293413\n",
            " 32.81553398 35.95075239 51.00702576 33.20207254]\n",
            "82800.0\n",
            "169.98315083655157\n",
            "[69.99 54.3  37.8  32.76 18.8 ]\n",
            "[69.99 54.3  37.8  32.76 18.8 ]\n"
          ]
        }
      ],
      "source": [
        "## 2. Introduction to Ndarrays ##\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "data_ndarray = np.array([10, 20, 30])\n",
        "\n",
        "## 4. NYC Taxi-Airport Data ##\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "# import nyc_taxi.csv as a list of lists\n",
        "f = open(\"/content/drive/MyDrive/Data/nyc_taxis.csv\", \"r\")\n",
        "taxi_list = list(csv.reader(f))\n",
        "\n",
        "# remove the header row\n",
        "taxi_list = taxi_list[1:]\n",
        "\n",
        "# convert all values to floats\n",
        "converted_taxi_list = []\n",
        "for row in taxi_list:\n",
        "    converted_row = []\n",
        "    for element in row:\n",
        "        converted_row.append(float(element))\n",
        "    converted_taxi_list.append(converted_row)\n",
        "\n",
        "# start writing your code below this comment\n",
        "taxi = np.array(converted_taxi_list)\n",
        "\n",
        "## 5. Array Shapes ##\n",
        "\n",
        "taxi_shape = np.shape(taxi) # ou taxi.shape\n",
        "print(taxi_shape)\n",
        "\n",
        "## 6. Selecting and Slicing Rows from Ndarrays ##\n",
        "\n",
        "row_0 = taxi[0]\n",
        "rows_391_to_500 = taxi[391:501]\n",
        "row_21_column_5 = taxi[21,5]\n",
        "\n",
        "## 7. Selecting Columns and Custom Slicing Ndarrays ##\n",
        "\n",
        "columns_1_4_7 = taxi[:,[1,4,7]]\n",
        "row_99_columns_5_to_8 = taxi[99,5:9]\n",
        "rows_100_to_200_column_14 = taxi[100:201,14]\n",
        "\n",
        "## 8. Vector Operations ##\n",
        "\n",
        "fare_amount = taxi[:,9]\n",
        "fees_amount = taxi[:,10]\n",
        "fare_and_fees = fare_amount + fees_amount\n",
        "print(fare_and_fees)\n",
        "\n",
        "## 9. Vector Operations (Continued) ##\n",
        "\n",
        "trip_distance_miles = taxi[:,7]\n",
        "trip_length_seconds = taxi[:,8]\n",
        "trip_length_hours = trip_length_seconds / 3600\n",
        "trip_mph = trip_distance_miles / trip_length_hours\n",
        "print(trip_mph[:10])\n",
        "\n",
        "## 10. Calculating Statistics for 1D Ndarrays ##\n",
        "\n",
        "mph_min = trip_mph.min()\n",
        "mph_max = trip_mph.max()\n",
        "print(mph_max)\n",
        "mph_mean = trip_mph.mean()\n",
        "print(mph_mean)\n",
        "\n",
        "## 12. Calculating Statistics for 2D Ndarrays ##\n",
        "\n",
        "# extract the first 5 rows only\n",
        "taxi_first_five = taxi[:5]\n",
        "# select columns: fare_amount, fees_amount, tolls_amount, and tip_amount\n",
        "fare_components = taxi_first_five[:, 9:13]\n",
        "fare_sums = fare_components.sum(axis=1)\n",
        "fare_totals = taxi_first_five[:,13]\n",
        "print(fare_totals)\n",
        "print(fare_sums)"
      ],
      "id": "2wMCROmTEQ__"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Boolean Indexing with NumPy"
      ],
      "metadata": {
        "id": "BnYfjFPxGPCW"
      },
      "id": "BnYfjFPxGPCW"
    },
    {
      "cell_type": "code",
      "source": [
        "## 1. Reading CSV files with NumPy ##\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "taxi = np.genfromtxt(\"/content/drive/MyDrive/Data/nyc_taxis.csv\", delimiter=',')\n",
        "taxi_shape = taxi.shape\n",
        "\n",
        "print(taxi)\n",
        "print(taxi_shape)\n",
        "\n",
        "## 2. Reading CSV Files with NumPy (Continued) ##\n",
        "\n",
        "taxi = np.genfromtxt(\"/content/drive/MyDrive/Data/nyc_taxis.csv\", delimiter=',')\n",
        "taxi_header_removed = taxi[1:]\n",
        "removed_shape = taxi_header_removed.shape\n",
        "\n",
        "taxi_header_skipped = np.genfromtxt(\"/content/drive/MyDrive/Data/nyc_taxis.csv\", delimiter=',', skip_header=1)\n",
        "skipped_shape = taxi_header_skipped.shape\n",
        "\n",
        "print(\"First 5 rows of taxi_header_removed:\")\n",
        "print(taxi_header_removed[:5])\n",
        "\n",
        "print(\"\\nFirst 5 rows of taxi_header_skipped:\")\n",
        "print(taxi_header_skipped[:5])\n",
        "\n",
        "print(\"\\nShape of taxi_header_removed:\", removed_shape)\n",
        "print(\"Shape of taxi_header_skipped:\", skipped_shape)\n",
        "\n",
        "## 3. Boolean Arrays ##\n",
        "\n",
        "a = np.array([1, 2, 3, 4, 5])\n",
        "b = np.array([\"blue\", \"blue\", \"red\", \"blue\"])\n",
        "c = np.array([80.0, 103.4, 96.9, 200.3])\n",
        "\n",
        "a_bool = a < 3\n",
        "b_bool = b == \"blue\"\n",
        "c_bool = c > 100\n",
        "\n",
        "print(a_bool)\n",
        "print(b_bool)\n",
        "print(c_bool)\n",
        "\n",
        "## 4. Boolean Indexing with 1D ndarrays ##\n",
        "\n",
        "pickup_month = taxi[:, 1]\n",
        "\n",
        "january_bool = pickup_month == 1\n",
        "january = pickup_month[january_bool]\n",
        "january_rides = january.shape[0]\n",
        "print(january_rides)\n",
        "\n",
        "february_bool = pickup_month == 2\n",
        "february = pickup_month[february_bool]\n",
        "february_rides = february.shape[0]\n",
        "print(february_rides)\n",
        "\n",
        "## 5. Boolean Indexing with 2D Ndarrays ##\n",
        "\n",
        "tip_amount = taxi[:,12]\n",
        "tip_bool = tip_amount > 20\n",
        "top_tips = taxi[tip_bool, 5:14]\n",
        "\n",
        "## 6. Assigning Values in Ndarrays ##\n",
        "\n",
        "# this creates a copy of our taxi ndarray\n",
        "taxi_copy = taxi.copy()\n",
        "\n",
        "taxi_copy[1066,5] = 1\n",
        "\n",
        "taxi_copy[:,0] = 16\n",
        "\n",
        "taxi_copy[550:552,7] = taxi_copy[:,7].mean()\n",
        "rows_550_551 = taxi_copy[550:552]\n",
        "\n",
        "## 7. Assignment Using Boolean Arrays ##\n",
        "\n",
        "# this creates a copy of our taxi ndarray\n",
        "taxi_copy = taxi.copy()\n",
        "\n",
        "trip_length = taxi_copy[:,8]\n",
        "trip_length[trip_length < 60] = 0\n",
        "\n",
        "## 8. Assignment Using Boolean Arrays (Continued) ##\n",
        "\n",
        "# create a new array filled with `0`\n",
        "zeros = np.zeros([taxi.shape[0], 1])\n",
        "# append the array to the taxi data to create a new column\n",
        "taxi_modified = np.concatenate([taxi, zeros], axis=1)\n",
        "# inspect the last five columns of the first ten rows\n",
        "print(taxi_modified[:10, -5:])\n",
        "\n",
        "taxi_modified[taxi_modified[:,6] == 2, 15] = 1\n",
        "taxi_modified[taxi_modified[:,6] == 3, 15] = 1\n",
        "taxi_modified[taxi_modified[:,6] == 5, 15] = 1\n",
        "\n",
        "## 9. Challenge: Which Is the Busiest Airport? ##\n",
        "\n",
        "jfk = taxi[taxi[:,5] == 2,]\n",
        "jfk_count = jfk.shape[0]\n",
        "print(jfk_count)\n",
        "\n",
        "laguardia = taxi[taxi[:,5] == 3,]\n",
        "laguardia_count = laguardia.shape[0]\n",
        "print(laguardia_count)\n",
        "\n",
        "newark = taxi[taxi[:,5] == 5,]\n",
        "newark_count = newark.shape[0]\n",
        "print(newark_count)\n",
        "\n",
        "busiest_airport = \"laguardia\"\n",
        "\n",
        "## 10. Challenge: Calculating Statistics for Trips on Clean Data ##\n",
        "\n",
        "trip_distance = taxi[:, 7] # trip distance in miles\n",
        "trip_length = taxi[:, 8] / 3600 # trip length in hours\n",
        "trip_mph = trip_distance / trip_length # average trip speed in mph\n",
        "\n",
        "cleaned_taxi = taxi[trip_mph < 100]\n",
        "\n",
        "mean_distance = cleaned_taxi[:,7].mean()\n",
        "mean_length = cleaned_taxi[:,8].mean()\n",
        "mean_total_amount = cleaned_taxi[:,13].mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQ9zkENGWSFT",
        "outputId": "e36d8812-bae4-41e2-cf8d-20e953b0d512"
      },
      "id": "BQ9zkENGWSFT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[      nan       nan       nan ...       nan       nan       nan]\n",
            " [2.016e+03 1.000e+00 1.000e+00 ... 1.165e+01 6.999e+01 1.000e+00]\n",
            " [2.016e+03 1.000e+00 1.000e+00 ... 8.000e+00 5.430e+01 1.000e+00]\n",
            " ...\n",
            " [2.016e+03 6.000e+00 3.000e+01 ... 5.000e+00 6.334e+01 1.000e+00]\n",
            " [2.016e+03 6.000e+00 3.000e+01 ... 8.950e+00 4.475e+01 1.000e+00]\n",
            " [2.016e+03 6.000e+00 3.000e+01 ... 0.000e+00 5.484e+01 2.000e+00]]\n",
            "(2014, 15)\n",
            "First 5 rows of taxi_header_removed:\n",
            "[[2.016e+03 1.000e+00 1.000e+00 5.000e+00 0.000e+00 2.000e+00 4.000e+00\n",
            "  2.100e+01 2.037e+03 5.200e+01 8.000e-01 5.540e+00 1.165e+01 6.999e+01\n",
            "  1.000e+00]\n",
            " [2.016e+03 1.000e+00 1.000e+00 5.000e+00 0.000e+00 2.000e+00 1.000e+00\n",
            "  1.629e+01 1.520e+03 4.500e+01 1.300e+00 0.000e+00 8.000e+00 5.430e+01\n",
            "  1.000e+00]\n",
            " [2.016e+03 1.000e+00 1.000e+00 5.000e+00 0.000e+00 2.000e+00 6.000e+00\n",
            "  1.270e+01 1.462e+03 3.650e+01 1.300e+00 0.000e+00 0.000e+00 3.780e+01\n",
            "  2.000e+00]\n",
            " [2.016e+03 1.000e+00 1.000e+00 5.000e+00 0.000e+00 2.000e+00 6.000e+00\n",
            "  8.700e+00 1.210e+03 2.600e+01 1.300e+00 0.000e+00 5.460e+00 3.276e+01\n",
            "  1.000e+00]\n",
            " [2.016e+03 1.000e+00 1.000e+00 5.000e+00 0.000e+00 2.000e+00 6.000e+00\n",
            "  5.560e+00 7.590e+02 1.750e+01 1.300e+00 0.000e+00 0.000e+00 1.880e+01\n",
            "  2.000e+00]]\n",
            "\n",
            "First 5 rows of taxi_header_skipped:\n",
            "[[2.016e+03 1.000e+00 1.000e+00 5.000e+00 0.000e+00 2.000e+00 4.000e+00\n",
            "  2.100e+01 2.037e+03 5.200e+01 8.000e-01 5.540e+00 1.165e+01 6.999e+01\n",
            "  1.000e+00]\n",
            " [2.016e+03 1.000e+00 1.000e+00 5.000e+00 0.000e+00 2.000e+00 1.000e+00\n",
            "  1.629e+01 1.520e+03 4.500e+01 1.300e+00 0.000e+00 8.000e+00 5.430e+01\n",
            "  1.000e+00]\n",
            " [2.016e+03 1.000e+00 1.000e+00 5.000e+00 0.000e+00 2.000e+00 6.000e+00\n",
            "  1.270e+01 1.462e+03 3.650e+01 1.300e+00 0.000e+00 0.000e+00 3.780e+01\n",
            "  2.000e+00]\n",
            " [2.016e+03 1.000e+00 1.000e+00 5.000e+00 0.000e+00 2.000e+00 6.000e+00\n",
            "  8.700e+00 1.210e+03 2.600e+01 1.300e+00 0.000e+00 5.460e+00 3.276e+01\n",
            "  1.000e+00]\n",
            " [2.016e+03 1.000e+00 1.000e+00 5.000e+00 0.000e+00 2.000e+00 6.000e+00\n",
            "  5.560e+00 7.590e+02 1.750e+01 1.300e+00 0.000e+00 0.000e+00 1.880e+01\n",
            "  2.000e+00]]\n",
            "\n",
            "Shape of taxi_header_removed: (2013, 15)\n",
            "Shape of taxi_header_skipped: (2013, 15)\n",
            "[ True  True False False False]\n",
            "[ True  True False  True]\n",
            "[False  True False  True]\n",
            "800\n",
            "176\n",
            "[[   nan    nan    nan    nan   0.  ]\n",
            " [  5.54  11.65  69.99   1.     0.  ]\n",
            " [  0.     8.    54.3    1.     0.  ]\n",
            " [  0.     0.    37.8    2.     0.  ]\n",
            " [  0.     5.46  32.76   1.     0.  ]\n",
            " [  0.     0.    18.8    2.     0.  ]\n",
            " [  0.    52.8  105.6    1.     0.  ]\n",
            " [  0.     6.45  32.25   1.     0.  ]\n",
            " [  0.     0.    22.8    2.     0.  ]\n",
            " [ 11.08  10.   131.38   1.     0.  ]]\n",
            "724\n",
            "755\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Introduction to Pandas"
      ],
      "metadata": {
        "id": "9IA5EdQUZPcz"
      },
      "id": "9IA5EdQUZPcz"
    },
    {
      "cell_type": "code",
      "source": [
        "## 2. Introduction to the Data ##\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "f500 = pd.read_csv(\"/content/drive/MyDrive/Data/f500.csv\", index_col=0)\n",
        "f500.index.name = None\n",
        "\n",
        "f500_type = type(f500)\n",
        "f500_shape = f500.shape\n",
        "print(f500_type)\n",
        "print(f500_shape)\n",
        "\n",
        "## 3. Introducing DataFrames ##\n",
        "\n",
        "f500_top_6 = f500.head(6)\n",
        "f500_bottom_8 = f500.tail(8)\n",
        "\n",
        "## 4. Introducing DataFrames (Continued) ##\n",
        "\n",
        "f500.info()\n",
        "\n",
        "float64_dtype = 3\n",
        "int64_dtype = 7\n",
        "object_dtype = 6\n",
        "\n",
        "## 5. Selecting a Column from a DataFrame by Label ##\n",
        "\n",
        "industries = f500[\"industry\"]\n",
        "industries_type = type(industries)\n",
        "print(industries)\n",
        "print(industries_type)\n",
        "\n",
        "## 7. Selecting Columns from a DataFrame by Label (Continued) ##\n",
        "\n",
        "countries = f500[\"country\"]\n",
        "revenues_years = f500[[\"revenues\", \"years_on_global_500_list\"]]\n",
        "ceo_to_sector = f500.loc[:,\"ceo\":\"sector\"]\n",
        "print(countries)\n",
        "\n",
        "## 8. Selecting Rows from a DataFrame by Label ##\n",
        "\n",
        "toyota = f500.loc[\"Toyota Motor\"]\n",
        "drink_companies = f500.loc[[\"Anheuser-Busch InBev\", \"Coca-Cola\", \"Heineken Holding\"]]\n",
        "middle_companies = f500[\"Tata Motors\":\"Nationwide\"]\n",
        "print(toyota)\n",
        "\n",
        "## 10. Value Counts Method ##\n",
        "\n",
        "countries = f500[\"country\"]\n",
        "country_counts = countries.value_counts()\n",
        "top_country = \"USA\"\n",
        "\n",
        "hq_locations = f500[\"hq_location\"]\n",
        "hql_counts = hq_locations.value_counts()\n",
        "top_hq_city = \"Beijing, China\"\n",
        "\n",
        "## 11. Selecting Items from a Series by Label ##\n",
        "\n",
        "countries = f500[\"country\"]\n",
        "country_counts = countries.value_counts()\n",
        "india = country_counts[\"India\"]\n",
        "north_america = country_counts[[\"USA\", \"Canada\", \"Mexico\"]]\n",
        "japan_to_spain = country_counts[\"Japan\":\"Spain\"]\n",
        "print(type(japan_to_spain))\n",
        "\n",
        "## 12. Summary Challenge ##\n",
        "\n",
        "big_movers = f500.loc[[\"Aviva\" , \"HP\" , \"JD.com\" , \"BHP Billiton\"] , [\"rank\" , \"previous_rank\"]]\n",
        "bottom_companies = f500.loc[\"National Grid\":\"AutoNation\", [\"rank\", \"sector\", \"country\"]]\n",
        "revenue_giants = f500.loc[[\"Apple\", \"Industrial & Commercial Bank of China\", \"China Construction Bank\", \"Agricultural Bank of China\"] , \"revenues\":\"profit_change\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmXmQKUDZOCZ",
        "outputId": "19bcaac4-6b71-4653-cacd-fbda960adadc"
      },
      "id": "BmXmQKUDZOCZ",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "(500, 16)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 500 entries, Walmart to AutoNation\n",
            "Data columns (total 16 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   rank                      500 non-null    int64  \n",
            " 1   revenues                  500 non-null    int64  \n",
            " 2   revenue_change            498 non-null    float64\n",
            " 3   profits                   499 non-null    float64\n",
            " 4   assets                    500 non-null    int64  \n",
            " 5   profit_change             436 non-null    float64\n",
            " 6   ceo                       500 non-null    object \n",
            " 7   industry                  500 non-null    object \n",
            " 8   sector                    500 non-null    object \n",
            " 9   previous_rank             500 non-null    int64  \n",
            " 10  country                   500 non-null    object \n",
            " 11  hq_location               500 non-null    object \n",
            " 12  website                   500 non-null    object \n",
            " 13  years_on_global_500_list  500 non-null    int64  \n",
            " 14  employees                 500 non-null    int64  \n",
            " 15  total_stockholder_equity  500 non-null    int64  \n",
            "dtypes: float64(3), int64(7), object(6)\n",
            "memory usage: 66.4+ KB\n",
            "Walmart                                     General Merchandisers\n",
            "State Grid                                              Utilities\n",
            "Sinopec Group                                  Petroleum Refining\n",
            "China National Petroleum                       Petroleum Refining\n",
            "Toyota Motor                             Motor Vehicles and Parts\n",
            "                                               ...               \n",
            "Teva Pharmaceutical Industries                    Pharmaceuticals\n",
            "New China Life Insurance          Insurance: Life, Health (stock)\n",
            "Wm. Morrison Supermarkets                    Food and Drug Stores\n",
            "TUI                                               Travel Services\n",
            "AutoNation                                    Specialty Retailers\n",
            "Name: industry, Length: 500, dtype: object\n",
            "<class 'pandas.core.series.Series'>\n",
            "Walmart                               USA\n",
            "State Grid                          China\n",
            "Sinopec Group                       China\n",
            "China National Petroleum            China\n",
            "Toyota Motor                        Japan\n",
            "                                   ...   \n",
            "Teva Pharmaceutical Industries     Israel\n",
            "New China Life Insurance            China\n",
            "Wm. Morrison Supermarkets         Britain\n",
            "TUI                               Germany\n",
            "AutoNation                            USA\n",
            "Name: country, Length: 500, dtype: object\n",
            "rank                                                   5\n",
            "revenues                                          254694\n",
            "revenue_change                                       7.7\n",
            "profits                                          16899.3\n",
            "assets                                            437575\n",
            "profit_change                                      -12.3\n",
            "ceo                                          Akio Toyoda\n",
            "industry                        Motor Vehicles and Parts\n",
            "sector                            Motor Vehicles & Parts\n",
            "previous_rank                                          8\n",
            "country                                            Japan\n",
            "hq_location                                Toyota, Japan\n",
            "website                     http://www.toyota-global.com\n",
            "years_on_global_500_list                              23\n",
            "employees                                         364445\n",
            "total_stockholder_equity                          157210\n",
            "Name: Toyota Motor, dtype: object\n",
            "<class 'pandas.core.series.Series'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4 Exploring Data with Pandas : Fundamentals"
      ],
      "metadata": {
        "id": "0C62yZof_zAM"
      },
      "id": "0C62yZof_zAM"
    },
    {
      "cell_type": "code",
      "source": [
        "## 1. Introduction to the Data ##\n",
        "\n",
        "f500_head = f500.head(10)\n",
        "f500.info()\n",
        "\n",
        "## 2. Vectorized Operations ##\n",
        "\n",
        "rank_change = f500[\"previous_rank\"] - f500[\"rank\"]\n",
        "\n",
        "## 3. Series Data Exploration Methods ##\n",
        "\n",
        "rank_change =  f500[\"previous_rank\"] - f500[\"rank\"]\n",
        "rank_change_max = rank_change.max()\n",
        "rank_change_min = rank_change.min()\n",
        "\n",
        "## 4. Series Describe Method ##\n",
        "\n",
        "rank = f500[\"rank\"]\n",
        "rank_desc = rank.describe()\n",
        "prev_rank = f500[\"previous_rank\"]\n",
        "prev_rank_desc = prev_rank.describe()\n",
        "\n",
        "## 5. Method Chaining ##\n",
        "\n",
        "zero_previous_rank = f500[\"previous_rank\"].value_counts().loc[0]\n",
        "\n",
        "## 6. Dataframe Exploration Methods ##\n",
        "\n",
        "max_f500 = f500.max(numeric_only = \"True\")\n",
        "\n",
        "## 7. Dataframe Describe Method ##\n",
        "\n",
        "f500_desc = f500.describe()\n",
        "\n",
        "## 8. Assignment with pandas ##\n",
        "\n",
        "f500.loc[\"Dow Chemical\", \"ceo\"] = \"Jim Fitterling\"\n",
        "\n",
        "## 9. Using Boolean Indexing with pandas Objects ##\n",
        "\n",
        "motor_bool = f500[\"industry\"] == \"Motor Vehicles and Parts\"\n",
        "motor_countries = f500.loc[motor_bool, \"country\"]\n",
        "\n",
        "## 10. Using Boolean Arrays to Assign Values ##\n",
        "\n",
        "import numpy as np\n",
        "prev_rank_before = f500[\"previous_rank\"].value_counts(dropna=False).head()\n",
        "f500.loc[f500[\"previous_rank\"] == 0, \"previous_rank\"] = np.nan\n",
        "\n",
        "prev_rank_after = f500[\"previous_rank\"].value_counts(dropna=False).head()\n",
        "\n",
        "## 11. Creating New Columns ##\n",
        "\n",
        "f500[\"rank_change\"] = f500[\"previous_rank\"] - f500[\"rank\"]\n",
        "rank_change_desc = f500[\"rank_change\"].describe()\n",
        "\n",
        "## 12. Challenge: Top Performers by Country ##\n",
        "\n",
        "industry_usa_bool = f500[f500[\"country\"] == \"USA\"]\n",
        "industry_usa = industry_usa_bool[\"industry\"].value_counts().head(2)\n",
        "print(industry_usa)\n",
        "sector_china_bool = f500[f500[\"country\"] == \"China\"]\n",
        "sector_china = sector_china_bool[\"sector\"].value_counts().head(3)\n",
        "print(sector_china)"
      ],
      "metadata": {
        "id": "KGxggH9e_x8M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37f06c66-eaf8-4472-eb94-a42764900140"
      },
      "id": "KGxggH9e_x8M",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 500 entries, Walmart to AutoNation\n",
            "Data columns (total 16 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   rank                      500 non-null    int64  \n",
            " 1   revenues                  500 non-null    int64  \n",
            " 2   revenue_change            498 non-null    float64\n",
            " 3   profits                   499 non-null    float64\n",
            " 4   assets                    500 non-null    int64  \n",
            " 5   profit_change             436 non-null    float64\n",
            " 6   ceo                       500 non-null    object \n",
            " 7   industry                  500 non-null    object \n",
            " 8   sector                    500 non-null    object \n",
            " 9   previous_rank             500 non-null    int64  \n",
            " 10  country                   500 non-null    object \n",
            " 11  hq_location               500 non-null    object \n",
            " 12  website                   500 non-null    object \n",
            " 13  years_on_global_500_list  500 non-null    int64  \n",
            " 14  employees                 500 non-null    int64  \n",
            " 15  total_stockholder_equity  500 non-null    int64  \n",
            "dtypes: float64(3), int64(7), object(6)\n",
            "memory usage: 66.4+ KB\n",
            "industry\n",
            "Banks: Commercial and Savings               8\n",
            "Insurance: Property and Casualty (Stock)    7\n",
            "Name: count, dtype: int64\n",
            "sector\n",
            "Financials     25\n",
            "Energy         22\n",
            "Wholesalers     9\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.5 Exploring Data with Pandas: Intermediate"
      ],
      "metadata": {
        "id": "S8UpYJiqG45N"
      },
      "id": "S8UpYJiqG45N"
    },
    {
      "cell_type": "code",
      "source": [
        "## 1. Introduction ##\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# read the dataset into a pandas dataframe\n",
        "f500 = pd.read_csv(\"/content/drive/MyDrive/Data/f500.csv\", index_col=0)\n",
        "f500.index.name = None\n",
        "\n",
        "# replace 0 values in the \"previous_rank\" column with NaN\n",
        "f500.loc[f500[\"previous_rank\"] == 0, \"previous_rank\"] = np.nan\n",
        "\n",
        "f500_selection = f500[[\"rank\", \"revenues\", \"revenue_change\"]].head()\n",
        "\n",
        "## 2. Reading CSV Files with pandas ##\n",
        "\n",
        "f500 = pd.read_csv(\"/content/drive/MyDrive/Data/f500.csv\")\n",
        "f500.index.name = \"Company\"\n",
        "f500.columns.name = \"Metric\"\n",
        "f500.loc[f500[\"previous_rank\"] == 0, \"previous_rank\"] = np.nan\n",
        "\n",
        "## 3. Using iloc to Select by Integer Location ##\n",
        "\n",
        "fifth_row = f500.iloc[4]\n",
        "company_value = f500.iloc[0,0]\n",
        "\n",
        "## 4. Using iloc to Select by Integer Location (Continued) ##\n",
        "\n",
        "first_three_rows = f500[0:3]\n",
        "first_seventh_row_slice = f500.iloc[[0, 6], 0:5]\n",
        "\n",
        "## 5. Using pandas Methods to Create Boolean Masks ##\n",
        "\n",
        "prev_rank_null = f500[\"previous_rank\"].isnull()\n",
        "null_prev_rank = f500[prev_rank_null][[\"company\",\"rank\",\"previous_rank\"]]\n",
        "\n",
        "## 6. Working with Integer Labels ##\n",
        "\n",
        "prev_rank_is_null = f500[f500[\"previous_rank\"].isnull()]\n",
        "top5_null_prev_rank = prev_rank_is_null.iloc[0:5]\n",
        "\n",
        "## 7. Pandas Index Alignment ##\n",
        "\n",
        "profited = f500[f500[\"profits\"].notnull()]\n",
        "costs = profited[\"revenues\"] - profited[\"profits\"]\n",
        "f500[\"costs\"] = costs\n",
        "\n",
        "## 8. Using Boolean Operators ##\n",
        "\n",
        "large_revenue = f500[\"revenues\"] > 100000\n",
        "negative_profits = f500[\"profits\"] < 0\n",
        "combined = large_revenue & negative_profits\n",
        "big_rev_neg_profit = f500.loc[combined,:]\n",
        "\n",
        "## 9. Using Boolean Operators (Continued) ##\n",
        "\n",
        "brazil_venezuela = f500[(f500[\"country\"] == \"Brazil\") | (f500[\"country\"] == \"Venezuela\")]\n",
        "tech_outside_usa = f500[(f500[\"sector\"] == \"Technology\") & ~(f500[\"country\"] == \"USA\")].head()\n",
        "\n",
        "## 10. Sorting Values ##\n",
        "\n",
        "selected_rows = f500[f500[\"country\"] == \"Japan\"]\n",
        "sorted_rows = selected_rows.sort_values(\"profits\", ascending=False)\n",
        "top_japanese_company = sorted_rows.iloc[0][[\"company\",\"profits\"]]\n",
        "print(top_japanese_company)\n",
        "\n",
        "## 11. Using Loops with pandas ##\n",
        "\n",
        "top_employer_by_country = {}\n",
        "\n",
        "# Create an array of unique values from the country column\n",
        "countries = f500[\"country\"].unique()\n",
        "\n",
        "for c in countries:\n",
        "    # Select only the rows that have a country name equal to the current iteration\n",
        "    selected_rows = f500[f500[\"country\"] == c]\n",
        "\n",
        "    # Sort those rows by the employees column in descending order\n",
        "    sorted_rows = selected_rows.sort_values(\"employees\", ascending=False)\n",
        "\n",
        "    # Select the first row from the sorted dataframe\n",
        "    first = sorted_rows.iloc[0]\n",
        "\n",
        "    # Extract the company name from the company column of the first row\n",
        "    top_employer = first[\"company\"]\n",
        "\n",
        "    # Assign the results to the top_employer_by_country dictionary\n",
        "    top_employer_by_country[c] = top_employer\n",
        "\n",
        "## 12. Challenge: Calculating Return on Assets by Sector ##\n",
        "\n",
        "f500[\"roa\"] = f500[\"profits\"] / f500[\"assets\"]\n",
        "\n",
        "top_roa_by_sector = {}\n",
        "\n",
        "sectors = f500[\"sector\"].unique()\n",
        "\n",
        "for s in sectors:\n",
        "    selected_rows = f500[f500[\"sector\"] == s]\n",
        "    sorted_rows = selected_rows.sort_values(\"roa\", ascending=False)\n",
        "    first = sorted_rows.iloc[0]\n",
        "    top_roa = first[\"company\"]\n",
        "    top_roa_by_sector[s] = top_roa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C25HgsgBZ2LI",
        "outputId": "f4928f33-55ae-472f-ef38-7e048fddd718"
      },
      "id": "C25HgsgBZ2LI",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metric\n",
            "company    Toyota Motor\n",
            "profits         16899.3\n",
            "Name: 4, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.6 Data Cleaning Basics"
      ],
      "metadata": {
        "id": "idXlI2quG9JS"
      },
      "id": "idXlI2quG9JS"
    },
    {
      "cell_type": "code",
      "source": [
        "## 1. Reading CSV Files with Encodings ##\n",
        "\n",
        "from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "laptops = pd.read_csv(\"/content/drive/MyDrive/Data/laptops.csv\", encoding=\"latin1\")\n",
        "print(laptops.info())\n",
        "\n",
        "## 2. Cleaning Column Names ##\n",
        "\n",
        "new_columns = []\n",
        "\n",
        "for c in laptops.columns:\n",
        "    c = c.strip()\n",
        "    new_columns.append(c)\n",
        "\n",
        "laptops.columns = new_columns\n",
        "\n",
        "## 3. Cleaning Column Names (Continued) ##\n",
        "\n",
        "def clean_col(col):\n",
        "    col = col.strip()\n",
        "    col = col.replace(\"Operating System\",\"os\")\n",
        "    col = col.replace(\" \",\"_\")\n",
        "    col = col.replace(\"(\",\"\")\n",
        "    col = col.replace(\")\",\"\")\n",
        "    col = col.lower()\n",
        "    return col\n",
        "\n",
        "new_columns = []\n",
        "for c in laptops.columns:\n",
        "    c = clean_col(c)\n",
        "    new_columns.append(c)\n",
        "\n",
        "laptops.columns = new_columns\n",
        "\n",
        "## 4. Converting String Columns to Numeric ##\n",
        "\n",
        "unique_ram = laptops[\"ram\"].unique()\n",
        "print(unique_ram)\n",
        "\n",
        "## 5. Removing Non-Digit Characters ##\n",
        "\n",
        "laptops[\"screen_size\"] = laptops[\"screen_size\"].str.replace('\"', '')\n",
        "laptops[\"ram\"] = laptops[\"ram\"].replace('GB','')\n",
        "\n",
        "## 6. Converting Columns to Numeric dtypes ##\n",
        "\n",
        "laptops[\"screen_size\"] = laptops[\"screen_size\"].astype(float)\n",
        "#laptops[\"ram\"] = laptops[\"ram\"].astype(int)\n",
        "print(laptops[\"ram\"].unique())\n",
        "print(\"`ram` dtype:\", laptops[\"ram\"].dtype)\n",
        "\n",
        "## 7. Renaming Columns ##\n",
        "\n",
        "laptops.rename({\"screen_size\": \"screen_size_inches\"}, axis=1, inplace=True)\n",
        "laptops.rename({\"ram\": \"ram_gb\"}, axis=1, inplace=True)\n",
        "ram_gb_desc = laptops[\"ram_gb\"].describe()\n",
        "print(ram_gb_desc)\n",
        "\n",
        "## 8. Extracting Values from Strings ##\n",
        "\n",
        "gpu_split = laptops[\"gpu\"].str.split()\n",
        "laptops[\"gpu_manufacturer\"] = gpu_split.str[0]\n",
        "gpu_manufacturer_counts = laptops[\"gpu_manufacturer\"].value_counts()\n",
        "laptops[\"cpu_manufacturer\"] = laptops[\"cpu\"].str.split().str[0]\n",
        "cpu_manufacturer_counts = laptops[\"cpu_manufacturer\"].value_counts()\n",
        "\n",
        "## 9. Correcting Bad Values ##\n",
        "\n",
        "print(laptops[\"os\"].unique())\n",
        "mapping_dict = {\"macOS\" : \"macOS\", \"No OS\" : \"No OS\", \"Windows\" : \"Windows\", \"Mac OS\" : \"macOS\", \"Linux\" : \"Linux\", \"Android\" : \"Android\", \"Chrome OS\" : \"Chrome OS\"}\n",
        "laptops[\"os\"] = laptops[\"os\"].map(mapping_dict)\n",
        "print(laptops[\"os\"].value_counts())\n",
        "\n",
        "## 10. Dropping Missing Values ##\n",
        "\n",
        "laptops_no_null_rows = laptops.dropna()\n",
        "laptops_no_null_cols = laptops.dropna(axis=1)\n",
        "\n",
        "## 11. Filling Missing Values ##\n",
        "\n",
        "value_counts_before = laptops.loc[laptops[\"os_version\"].isnull(), \"os\"].value_counts()\n",
        "laptops.loc[laptops[\"os\"] == \"macOS\", \"os_version\"] = \"X\"\n",
        "laptops.loc[laptops[\"os\"] == \"No OS\", \"os_version\"] = \"Not Applicable\"\n",
        "value_counts_after = laptops.loc[laptops[\"os_version\"].isnull(), \"os\"].value_counts()\n",
        "\n",
        "## 12. Challenge: Clean a String Column ##\n",
        "\n",
        "weight_unique = laptops[\"weight\"].unique()\n",
        "laptops[\"weight\"] = laptops[\"weight\"].str.replace(\"kgs\",\"\")\n",
        "laptops[\"weight\"] = laptops[\"weight\"].str.replace(\"kg\",\"\")\n",
        "laptops[\"weight\"] = laptops[\"weight\"].astype(float)\n",
        "laptops.rename({\"weight\": \"weight_kg\"}, axis=1, inplace=True)\n",
        "#laptops.to_csv('/tmp/laptops_cleaned.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUpgkLUuBCsd",
        "outputId": "16f3b93a-4eb0-4ab5-dbdd-fbb3b4d33419"
      },
      "id": "UUpgkLUuBCsd",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1303 entries, 0 to 1302\n",
            "Data columns (total 13 columns):\n",
            " #   Column                    Non-Null Count  Dtype \n",
            "---  ------                    --------------  ----- \n",
            " 0   Manufacturer              1303 non-null   object\n",
            " 1   Model Name                1303 non-null   object\n",
            " 2   Category                  1303 non-null   object\n",
            " 3   Screen Size               1303 non-null   object\n",
            " 4   Screen                    1303 non-null   object\n",
            " 5   CPU                       1303 non-null   object\n",
            " 6   RAM                       1303 non-null   object\n",
            " 7    Storage                  1303 non-null   object\n",
            " 8   GPU                       1303 non-null   object\n",
            " 9   Operating System          1303 non-null   object\n",
            " 10  Operating System Version  1133 non-null   object\n",
            " 11  Weight                    1303 non-null   object\n",
            " 12  Price (Euros)             1303 non-null   object\n",
            "dtypes: object(13)\n",
            "memory usage: 132.5+ KB\n",
            "None\n",
            "['8GB' '16GB' '4GB' '2GB' '12GB' '6GB' '32GB' '24GB' '64GB']\n",
            "['8GB' '16GB' '4GB' '2GB' '12GB' '6GB' '32GB' '24GB' '64GB']\n",
            "`ram` dtype: object\n",
            "count     1303\n",
            "unique       9\n",
            "top        8GB\n",
            "freq       619\n",
            "Name: ram_gb, dtype: object\n",
            "['macOS' 'No OS' 'Windows' 'Mac OS' 'Linux' 'Android' 'Chrome OS']\n",
            "os\n",
            "Windows      1125\n",
            "No OS          66\n",
            "Linux          62\n",
            "Chrome OS      27\n",
            "macOS          21\n",
            "Android         2\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Guided Project: Exploring eBay Car Sales Data"
      ],
      "metadata": {
        "id": "0_m07KsgJqpG"
      },
      "id": "0_m07KsgJqpG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "See project here : [\"Project_Pandas\"](https://colab.research.google.com/drive/1RQQ4SYa_uFOal4hYBpMHK77Mj_78kHz0)"
      ],
      "metadata": {
        "id": "os1-zJbrJ4ib"
      },
      "id": "os1-zJbrJ4ib"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kCxCQRXERAA"
      },
      "source": [
        "## 5. Conclusion\n",
        "- Ce que j’ai appris :\n",
        "\n",
        "  *   Comment la vectorisation accélère notre code\n",
        "  *   Les tableaux à n dimensions et les ndarrays de NumPy\n",
        "  *   Comment sélectionner des éléments spécifiques, des lignes, des colonnes, des tranches 1D et des tranches 2D à partir de ndarrays\n",
        "  *   Comment appliquer des calculs simples à des tableaux entiers\n",
        "  *   Comment la diffusion permet d'effectuer des opérations entre des ndarrays de formes différentes\n",
        "  *   Comment utiliser des méthodes vectorisées pour effectuer des calculs sur l'un ou l'autre axe des ndarrays\n",
        "\n",
        "  *   A utiliser `numpy.genfromtxt()` pour charger des données dans un ndarray\n",
        "  *   Les valeurs NaN et la manière dont elles peuvent affecter les données\n",
        "  *   Les tableaux booléens et comment les créer à l'aide d'opérateurs de comparaison\n",
        "  *   A utiliser l'indexation booléenne pour filtrer les valeurs dans les ndarrays unidimensionnels et bidimensionnels\n",
        "  *   L'attribution de nouvelles valeurs à un ndarray en fonction de leurs emplacements\n",
        "  *   L'attribution de nouvelles valeurs à un ndarray en fonction de leurs valeurs, à l'aide de l'indexation booléenne\n",
        "\n",
        "  *   Comment sélectionner des données à partir d'objets pandas à l'aide de tableaux booléens\n",
        "  *   Comment attribuer des données à l'aide d'étiquettes et de tableaux booléens\n",
        "  *   Comment créer de nouvelles colonnes dans pandas\n",
        "  *   De nombreuses nouvelles méthodes pour faciliter l’analyse des données dans Pandas\n",
        "\n",
        "  *   A sélectionner des colonnes, des lignes et des éléments individuels en utilisant leur emplacement entier\n",
        "  *   A utiliser `pd.read_csv()` pour lire les fichiers CSV dans pandas\n",
        "  *   A travailler avec des étiquettes d'axes entiers\n",
        "  *   A utiliser les méthodes pandas pour produire des tableaux booléens\n",
        "  *   A utiliser des opérateurs booléens pour combiner des comparaisons booléennes afin d'effectuer des sélections plus complexes\n",
        "  *   A utiliser des étiquettes d’index pour aligner les données\n",
        "  *   A utiliser l'agrégation pour effectuer une analyse avancée à l'aide d'une boucle for\n",
        "\n",
        "\n",
        "- Références : [Introduction to Pandas and NumPy for Data Analysis](https://www.dataquest.io/course/pandas-fundamentals/)."
      ],
      "id": "6kCxCQRXERAA"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
